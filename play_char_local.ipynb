{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from mingpt.model import GPT, GPTConfig\n",
    "from mingpt.trainer import Trainer, TrainerConfig\n",
    "from mingpt.utils import sample, set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom generator for training data.\n",
    "\n",
    "class CharDatasetGenerator(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, data, block_size, batch_size):\n",
    "        chars = sorted(list(set(data)))\n",
    "        data_size, vocab_size = len(data), len(chars)\n",
    "        print('data has %d characters, %d unique.' % (data_size, vocab_size))\n",
    "        \n",
    "        self.stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "        self.itos = { i:ch for i,ch in enumerate(chars) }\n",
    "        self.block_size = block_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        # number of batches\n",
    "        return math.ceil((len(self.data) - self.block_size) / self.batch_size)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # this idx is for a batch.\n",
    "        # want to return a batch of chunks, each of size block_size.\n",
    "        \n",
    "        chunk_idx_range = range(\n",
    "            idx * self.batch_size,\n",
    "            min((idx + 1) * self.batch_size, len(self.data) - self.block_size))\n",
    "        chunks = [self.get_chunk(chunk_idx) for chunk_idx in chunk_idx_range]\n",
    "        batch_x, batch_y = zip(*chunks)\n",
    "        \n",
    "        return np.array(batch_x), np.array(batch_y)\n",
    "        \n",
    "    def get_chunk(self, chunk_idx):\n",
    "        # grab a chunk of (block_size + 1) characters from the data\n",
    "        chunk = self.data[chunk_idx:chunk_idx + self.block_size + 1]\n",
    "        # encode every character to an integer\n",
    "        dix = [self.stoi[s] for s in chunk]\n",
    "        \n",
    "        x = dix[:-1]\n",
    "        y = dix[1:]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 25 # spatial extent of the model for its context\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 100000 characters, 61 unique.\n",
      "Batch_count: 196\n"
     ]
    }
   ],
   "source": [
    "text = open('input.txt', 'r').read()\n",
    "text = text[:100000]\n",
    "train_dataset = CharDatasetGenerator(text, block_size, batch_size)\n",
    "print(\"Batch_count:\", len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gpt\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  6100      \n",
      "_________________________________________________________________\n",
      "positional_encoding (Positio multiple                  2500      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "block (Block)                multiple                  121925    \n",
      "_________________________________________________________________\n",
      "block_1 (Block)              multiple                  121925    \n",
      "_________________________________________________________________\n",
      "layer_normalization_4 (Layer multiple                  200       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             multiple                  6100      \n",
      "=================================================================\n",
      "Total params: 258,750\n",
      "Trainable params: 257,500\n",
      "Non-trainable params: 1,250\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mconf = GPTConfig(train_dataset.vocab_size, train_dataset.block_size, n_layer=2,\n",
    "                  n_head=2, n_embd=100)\n",
    "model = GPT(mconf)\n",
    "\n",
    "model.build([train_dataset.batch_size, train_dataset.block_size])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "196/196 [==============================] - 186s 921ms/step - loss: 2.9737\n",
      "Epoch 2/10\n",
      "196/196 [==============================] - 174s 888ms/step - loss: 2.3528\n",
      "Epoch 3/10\n",
      "196/196 [==============================] - 165s 844ms/step - loss: 2.1983\n",
      "Epoch 4/10\n",
      "196/196 [==============================] - 169s 860ms/step - loss: 2.1071\n",
      "Epoch 5/10\n",
      "196/196 [==============================] - 164s 838ms/step - loss: 2.0344\n",
      "Epoch 6/10\n",
      "196/196 [==============================] - 170s 865ms/step - loss: 1.9995\n",
      "Epoch 7/10\n",
      "196/196 [==============================] - 160s 817ms/step - loss: 1.9394\n",
      "Epoch 8/10\n",
      "196/196 [==============================] - 160s 815ms/step - loss: 1.9247\n",
      "Epoch 9/10\n",
      "196/196 [==============================] - 160s 815ms/step - loss: 1.9063\n",
      "Epoch 10/10\n",
      "196/196 [==============================] - 160s 816ms/step - loss: 1.9005\n"
     ]
    }
   ],
   "source": [
    "# initialize a trainer instance and kick off training\n",
    "tconf = TrainerConfig(max_epochs=10, batch_size=train_dataset.batch_size,\n",
    "                      learning_rate=6e-4, lr_decay=True, warmup_steps=20,\n",
    "                      final_steps=len(train_dataset) * 10, num_workers=1)\n",
    "trainer = Trainer(model, train_dataset, None, tconf)\n",
    "trainer.train(tensorboard=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello theresem\n",
      "That you dando the pplows,-\n",
      "LENIUS:\n",
      "You army too there sor' ther cournd bre the the me sway, and you the solds\n",
      "Have pains.\n",
      "\n",
      "SICINIUS:\n",
      "He sold sharke to they his suld frucentunt in whus patces by warss and he be contughing and ance, and ming,\n",
      "Thing he sencins but he pares of is and the hear beeat a of carend he as steake thou have so the be a drighth hat my, his hould whathos fuide antle shim fird mure\n",
      "Than oun of ches\n",
      "What couls!\n",
      "The worth my but than yensear sof compliace\n",
      "Than the as hatt bearted-itiong.\n",
      "BBRUTUS:\n",
      "Secay ther.\n",
      "\n",
      "COMINIUS:\n",
      "No here miserve and there well.\n",
      "\n",
      "CORIOLANUS:\n",
      "Thin bertile sue not maning, the shows whith hem cinnd you with hous him all is of the sher thing whicen a the haven bare theey have of me the ave hum, mureds, nor iles\n",
      "Ye have with the he crintents aging of him agat what sech\n",
      "In world trrubely tis bode she bellites\n",
      "Hus an the trum.\n",
      "\n",
      "SSICINIUS:\n",
      "No them.\n",
      "SICINIUS:\n",
      "Or held praten, that: him nost thim banittizen:\n",
      "That wind the the corn prooce benert a beiner\n"
     ]
    }
   ],
   "source": [
    "context = \"Hello there\"\n",
    "x = np.array([train_dataset.stoi[s] for s in context]).reshape([1, len(context)])\n",
    "\n",
    "y = sample(model, x, 1000, sample=True, top_k=10)[0]\n",
    "completion = ''.join([train_dataset.itos[int(i)] for i in y])\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
